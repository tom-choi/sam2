{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def get_activation(activation_type):\n",
    "    \"\"\"Helper function to get activation layer\"\"\"\n",
    "    if activation_type.lower() == 'elu':\n",
    "        return nn.ELU()\n",
    "    elif activation_type.lower() == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif activation_type.lower() == 'leaky_relu':\n",
    "        return nn.LeakyReLU()\n",
    "    elif activation_type.lower() == 'sigmoid':\n",
    "        return nn.Sigmoid()\n",
    "    elif activation_type.lower() == 'tanh':\n",
    "        return nn.Tanh()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported activation type: {activation_type}\")\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int, batch_norm=False):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int) if batch_norm else nn.Identity()\n",
    "        )\n",
    "\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int) if batch_norm else nn.Identity()\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1) if batch_norm else nn.Identity(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "class Att_YNet(nn.Module):\n",
    "    def __init__(self, image_shape, activation='elu', feature_maps=[16, 32, 64, 128, 256],\n",
    "                 drop_values=[0.1, 0.1, 0.2, 0.2, 0.3], spatial_dropout=False, batch_norm=False,\n",
    "                 n_classes=1):\n",
    "        super(Att_YNet, self).__init__()\n",
    "\n",
    "        self.depth = len(feature_maps) - 1\n",
    "        self.activation = get_activation(activation)  # 使用辅助函数获取激活层\n",
    "        self.spatial_dropout = spatial_dropout\n",
    "        self.batch_norm = batch_norm\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder_blocks = nn.ModuleList()\n",
    "        in_channels = image_shape[0]  # 使用image_shape的第一个维度作为输入通道\n",
    "        for i in range(self.depth):\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels if i == 0 else feature_maps[i-1], feature_maps[i], 3, padding=1),\n",
    "                nn.BatchNorm2d(feature_maps[i]) if batch_norm else nn.Identity(),\n",
    "                self.activation,\n",
    "                nn.Dropout2d(drop_values[i]) if spatial_dropout else nn.Dropout(drop_values[i]),\n",
    "                nn.Conv2d(feature_maps[i], feature_maps[i], 3, padding=1),\n",
    "                nn.BatchNorm2d(feature_maps[i]) if batch_norm else nn.Identity(),\n",
    "                self.activation\n",
    "            )\n",
    "            self.encoder_blocks.append(block)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(feature_maps[-2], feature_maps[-1], 3, padding=1),\n",
    "            nn.BatchNorm2d(feature_maps[-1]) if batch_norm else nn.Identity(),\n",
    "            self.activation,\n",
    "            nn.Dropout2d(drop_values[-1]) if spatial_dropout else nn.Dropout(drop_values[-1]),\n",
    "            nn.Conv2d(feature_maps[-1], feature_maps[-1], 3, padding=1),\n",
    "            nn.BatchNorm2d(feature_maps[-1]) if batch_norm else nn.Identity(),\n",
    "            self.activation\n",
    "        )\n",
    "\n",
    "        # Decoder (UNet)\n",
    "        self.unet_decoder_blocks = nn.ModuleList()\n",
    "        self.attention_blocks = nn.ModuleList()\n",
    "        for i in range(self.depth-1, -1, -1):\n",
    "            self.attention_blocks.append(AttentionBlock(feature_maps[i], feature_maps[i], feature_maps[i]//2, batch_norm))\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(feature_maps[i]*2, feature_maps[i], 3, padding=1),\n",
    "                nn.BatchNorm2d(feature_maps[i]) if batch_norm else nn.Identity(),\n",
    "                self.activation,\n",
    "                nn.Dropout2d(drop_values[i]) if spatial_dropout else nn.Dropout(drop_values[i]),\n",
    "                nn.Conv2d(feature_maps[i], feature_maps[i], 3, padding=1),\n",
    "                nn.BatchNorm2d(feature_maps[i]) if batch_norm else nn.Identity(),\n",
    "                self.activation\n",
    "            )\n",
    "            self.unet_decoder_blocks.append(block)\n",
    "\n",
    "        # Decoder (AutoEncoder)\n",
    "        self.ae_decoder_blocks = nn.ModuleList()\n",
    "        for i in range(self.depth-1, -1, -1):\n",
    "            block = nn.Sequential(\n",
    "                nn.Conv2d(feature_maps[i+1] if i != self.depth-1 else feature_maps[-1], feature_maps[i], 3, padding=1),\n",
    "                nn.BatchNorm2d(feature_maps[i]) if batch_norm else nn.Identity(),\n",
    "                self.activation,\n",
    "                nn.Dropout2d(drop_values[i]) if spatial_dropout else nn.Dropout(drop_values[i]),\n",
    "                nn.Conv2d(feature_maps[i], feature_maps[i], 3, padding=1),\n",
    "                nn.BatchNorm2d(feature_maps[i]) if batch_norm else nn.Identity(),\n",
    "                self.activation\n",
    "            )\n",
    "            self.ae_decoder_blocks.append(block)\n",
    "\n",
    "        self.final_conv_mask = nn.Conv2d(feature_maps[0], n_classes, 1)\n",
    "        self.final_conv_img = nn.Conv2d(feature_maps[0], image_shape[0], 1)  # 输出通道数应与输入图像通道数相同\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        encoder_features = []\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x)\n",
    "            encoder_features.append(x)\n",
    "            x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        # UNet Decoder\n",
    "        unet_x = x\n",
    "        for i, block in enumerate(self.unet_decoder_blocks):\n",
    "            unet_x = F.interpolate(unet_x, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            attn = self.attention_blocks[i](unet_x, encoder_features[-(i+1)])\n",
    "            unet_x = torch.cat([unet_x, attn], dim=1)\n",
    "            unet_x = block(unet_x)\n",
    "\n",
    "        # AutoEncoder Decoder\n",
    "        ae_x = x\n",
    "        for block in self.ae_decoder_blocks:\n",
    "            ae_x = F.interpolate(ae_x, scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            ae_x = block(ae_x)\n",
    "\n",
    "        mask = torch.sigmoid(self.final_conv_mask(unet_x))\n",
    "        img = self.final_conv_img(ae_x)\n",
    "\n",
    "        return img, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'elu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 使用示例\u001b[39;00m\n\u001b[0;32m      2\u001b[0m image_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)  \u001b[38;5;66;03m# (C, H, W)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAtt_YNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39mimage_shape)\n\u001b[0;32m      5\u001b[0m img, mask \u001b[38;5;241m=\u001b[39m model(x)\n",
      "Cell \u001b[1;32mIn[2], line 40\u001b[0m, in \u001b[0;36mAtt_YNet.__init__\u001b[1;34m(self, image_shape, activation, feature_maps, drop_values, spatial_dropout, batch_norm, n_classes)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28msuper\u001b[39m(Att_YNet, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(feature_maps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m()\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_dropout \u001b[38;5;241m=\u001b[39m spatial_dropout\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norm \u001b[38;5;241m=\u001b[39m batch_norm\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'elu'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 使用示例\n",
    "image_shape = (3, 256, 256)  # (C, H, W)\n",
    "model = Att_YNet(image_shape)\n",
    "x = torch.randn(1, *image_shape)\n",
    "img, mask = model(x)\n",
    "print(f\"Image output shape: {img.shape}\")\n",
    "print(f\"Mask output shape: {mask.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
